{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "\n",
    "# Get projet name\n",
    "shell_output=!gcloud config get-value project 2> /dev/null\n",
    "PROJECT_ID=shell_output[0]\n",
    "\n",
    "# Set bucket name\n",
    "BUCKET_NAME=\"gs://\"+PROJECT_ID+\"-bucket-winequality\"\n",
    "\n",
    "# Create bucket\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root_wine/\"\n",
    "PIPELINE_ROOT\n",
    "\n",
    "USER_FLAG = \"--user\"\n",
    "#!gcloud auth login if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install virtual env \n",
    "python -m pip install --user virtualenv\n",
    "echo \"create env\"\n",
    "python -m venv vertex_venv\n",
    "#Add kernel to jupyter\n",
    "echo \"Add kernel to jupyter\"\n",
    "ipython kernel install --name \"vertex_env\" --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"pandas\", \"pyarrow\",  \"scikit-learn\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"get_wine_data.yaml\"\n",
    ")\n",
    "\n",
    "def get_wine_data(\n",
    "    url: str,\n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset]\n",
    "):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    \n",
    "    df_wine = pd.read_csv(url, delimiter=\";\")\n",
    "    df_wine['best_quality'] = [ 1 if x>=7 else 0 for x in df_wine.quality] \n",
    "    df_wine['target'] = df_wine.best_quality\n",
    "    df_wine = df_wine.drop(['quality', 'total sulfur dioxide', 'best_quality'], axis=1)\n",
    "   \n",
    "   \n",
    "    train, test = tts(df_wine, test_size=0.3)\n",
    "    train.to_csv(dataset_train.path + \".csv\" , index=False, encoding='utf-8-sig')\n",
    "    test.to_csv(dataset_test.path + \".csv\" , index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install = [\n",
    "        \"pandas\",\n",
    "        \"scikit-learn\",\n",
    "    ], base_image=\"python:3.9\",\n",
    ")\n",
    "def train_winequality(\n",
    "    dataset:  Input[Dataset],\n",
    "    model: Output[Model], \n",
    "):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "\n",
    "    data = pd.read_csv(dataset.path+\".csv\")\n",
    "    model_rf = RandomForestClassifier(n_estimators=10)\n",
    "    model_rf.fit(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "    model.metadata[\"framework\"] = \"RF\"\n",
    "    file_name = model.path + f\".pkl\"\n",
    "    with open(file_name, 'wb') as file:  \n",
    "        pickle.dump(model_rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install = [\n",
    "        \"pandas\",\n",
    "        \"scikit-learn\"\n",
    "    ], base_image=\"python:3.9\",\n",
    ")\n",
    "def winequality_evaluation(\n",
    "    test_set:  Input[Dataset],\n",
    "    rf_winequality_model: Input[Model],\n",
    "    thresholds_dict_str: str,\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    kpi: Output[Metrics]\n",
    ") -> NamedTuple(\"output\", [(\"deploy\", str)]):\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import pandas as pd\n",
    "    import logging \n",
    "    import pickle\n",
    "    from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score\n",
    "    import json\n",
    "    import typing\n",
    "\n",
    "    \n",
    "    def threshold_check(val1, val2):\n",
    "        cond = \"false\"\n",
    "        if val1 >= val2 :\n",
    "            cond = \"true\"\n",
    "        return cond\n",
    "\n",
    "    data = pd.read_csv(test_set.path+\".csv\")\n",
    "    model = RandomForestClassifier()\n",
    "    file_name = rf_winequality_model.path + \".pkl\"\n",
    "    with open(file_name, 'rb') as file:  \n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    y_test = data.drop(columns=[\"target\"])\n",
    "    y_target=data.target\n",
    "    y_pred = model.predict(y_test)\n",
    "    \n",
    "\n",
    "    y_scores =  model.predict_proba(data.drop(columns=[\"target\"]))[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(\n",
    "         y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
    "    )\n",
    "    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())  \n",
    "    \n",
    "    metrics.log_confusion_matrix(\n",
    "       [\"False\", \"True\"],\n",
    "       confusion_matrix(\n",
    "           data.target, y_pred\n",
    "       ).tolist(), \n",
    "    )\n",
    "    \n",
    "    accuracy = accuracy_score(data.target, y_pred.round())\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    rf_winequality_model.metadata[\"accuracy\"] = float(accuracy)\n",
    "    kpi.log_metric(\"accuracy\", float(accuracy))\n",
    "    deploy = threshold_check(float(accuracy), int(thresholds_dict['roc']))\n",
    "    return (deploy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\", \"scikit-learn==1.0.0\",  \"kfp\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"model_winequality_coponent.yml\"\n",
    ")\n",
    "def deploy_winequality(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    serving_container_image_uri : str, \n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project=project, location=region)\n",
    "\n",
    "    DISPLAY_NAME  = \"winequality\"\n",
    "    MODEL_NAME = \"winequality-rf\"\n",
    "    ENDPOINT_NAME = \"winequality_endpoint\"\n",
    "    \n",
    "    def create_endpoint():\n",
    "        endpoints = aiplatform.Endpoint.list(\n",
    "        filter='display_name=\"{}\"'.format(ENDPOINT_NAME),\n",
    "        order_by='create_time desc',\n",
    "        project=project, \n",
    "        location=region,\n",
    "        )\n",
    "        if len(endpoints) > 0:\n",
    "            endpoint = endpoints[0]  # most recently created\n",
    "        else:\n",
    "            endpoint = aiplatform.Endpoint.create(\n",
    "            display_name=ENDPOINT_NAME, project=project, location=region\n",
    "        )\n",
    "    endpoint = create_endpoint()   \n",
    "    \n",
    "    \n",
    "    #Import a model programmatically\n",
    "    model_upload = aiplatform.Model.upload(\n",
    "        display_name = DISPLAY_NAME, \n",
    "        artifact_uri = model.uri.replace(\"model\", \"\"),\n",
    "        serving_container_image_uri =  serving_container_image_uri,\n",
    "        serving_container_health_route=f\"/v1/models/{MODEL_NAME}\",\n",
    "        serving_container_predict_route=f\"/v1/models/{MODEL_NAME}:predict\",\n",
    "        serving_container_environment_variables={\n",
    "        \"MODEL_NAME\": MODEL_NAME,\n",
    "    },       \n",
    "    )\n",
    "    model_deploy = model_upload.deploy(\n",
    "        machine_type=\"n1-standard-4\", \n",
    "        endpoint=endpoint,\n",
    "        traffic_split={\"0\": 100},\n",
    "        deployed_model_display_name=DISPLAY_NAME,\n",
    "    )\n",
    "\n",
    "    # Save data to the output params\n",
    "    vertex_model.uri = model_deploy.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TIMESTAMP =datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "DISPLAY_NAME = 'pipeline-winequality-job{}'.format(TIMESTAMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"pipeline-winequality\",\n",
    "    \n",
    ")\n",
    "def pipeline(\n",
    "    url: str = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION, \n",
    "    display_name: str = DISPLAY_NAME,\n",
    "    api_endpoint: str = REGION+\"-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str = '{\"roc\":0.8}',\n",
    "    serving_container_image_uri: str = \"europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    "    ):\n",
    "    \n",
    "    data_op = get_wine_data(url)\n",
    "    train_model_op = train_winequality(data_op.outputs[\"dataset_train\"])\n",
    "    model_evaluation_op = winequality_evaluation(\n",
    "        test_set=data_op.outputs[\"dataset_test\"],\n",
    "        rf_winequality_model=train_model_op.outputs[\"model\"],\n",
    "        thresholds_dict_str = thresholds_dict_str, # I deploy the model anly if the model performance is above the threshold\n",
    "    )\n",
    "    \n",
    "    with dsl.Condition(\n",
    "        model_evaluation_op.outputs[\"deploy\"]==\"true\",\n",
    "        name=\"deploy-winequality\",\n",
    "    ):\n",
    "           \n",
    "        deploy_model_op = deploy_winequality(\n",
    "        model=train_model_op.outputs['model'],\n",
    "        project=project,\n",
    "        region=region, \n",
    "        serving_container_image_uri = serving_container_image_uri,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='ml_winequality.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pipeline = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"winequality-pipeline\",\n",
    "    template_path=\"ml_winequality.json\",\n",
    "    enable_caching=True,\n",
    "    location=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME=\"winequality_endpoint\"\n",
    "instance = [[1,2,3,2,1,2,3,6,7,10]]\n",
    "ENDPOINT_ID = !(gcloud ai endpoints list --region=$REGION \\\n",
    "              --format='value(ENDPOINT_ID)'\\\n",
    "              --filter=display_name=$ENDPOINT_NAME \\\n",
    "              --sort-by=creationTimeStamp | tail -1)\n",
    "ENDPOINT_ID = ENDPOINT_ID[1]\n",
    "\n",
    "def endpoint_predict(\n",
    "    project: str, location: str, instances: list, endpoint: str\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint)\n",
    "\n",
    "    prediction = endpoint.predict(instances=instances)\n",
    "    return prediction\n",
    "\n",
    "endpoint_predict(PROJECT_ID, REGION, instance, ENDPOINT_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11 (default, Jul 27 2021, 07:03:16) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98d7cd0e3241ea21cc39e19b2e113383bcc150574d314e390927903ba4bbfcbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
